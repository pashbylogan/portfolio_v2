[{"content":" \u0026ldquo;Interesting people are interested\u0026rdquo; ~my friend Matt \u0026ldquo;Anything you say before the word “but” does not count\u0026rdquo; ~Kevin Kelly ","permalink":"https://loganpashby.com/blog/quotes/","summary":" \u0026ldquo;Interesting people are interested\u0026rdquo; ~my friend Matt \u0026ldquo;Anything you say before the word “but” does not count\u0026rdquo; ~Kevin Kelly ","title":"Observations I Happen to Think Are True"},{"content":"Description Dead simple lasagna (uncooked noodles).\nIngredients Meat Sauce:\n1 pound lean ground beef (optional: Substitute italian sausage for some kick) 1 onion, chopped 1 (4.5 ounce) can mushrooms, drained 1 (28 ounce) jar spaghetti sauce Cheese Filling:\n1 (16 ounce) package cottage cheese 1 pint part-skim ricotta cheese 2 large eggs ¼ cup grated Parmesan cheese Other:\n1 (16 ounce) package lasagna noodles 8 ounces shredded mozzarella cheese, divided Directions Preheat the oven to 350 degrees F (175 degrees C). Make sauce: Heat a large skillet over medium-high heat. Cook and stir ground beef in the hot skillet until browned and crumbly, 5 to 7 minutes. Add onion and mushrooms; sauté until onions are transparent. Stir in pasta sauce and cook until heated through. Set aside. Make filling: Combine cottage cheese, ricotta, eggs, and Parmesan in a medium bowl and set aside. Spread a thin layer of meat sauce in the bottom of a 13x9-inch dish. Layer with uncooked lasagna noodles, cheese filling, mozzarella, and meat sauce. Continue layering until all components are used, reserving 1/2 cup mozzarella. Cover the dish with aluminum foil. Bake in the preheated oven for 45 minutes. Remove foil and top with reserved 1/2 cup mozzarella. Continue baking until cheese is melted, about 15 more minutes. Let lasagna stand for 10 to 15 minutes before serving. ","permalink":"https://loganpashby.com/recipes/lasagna/","summary":"Description Dead simple lasagna (uncooked noodles).\nIngredients Meat Sauce:\n1 pound lean ground beef (optional: Substitute italian sausage for some kick) 1 onion, chopped 1 (4.5 ounce) can mushrooms, drained 1 (28 ounce) jar spaghetti sauce Cheese Filling:\n1 (16 ounce) package cottage cheese 1 pint part-skim ricotta cheese 2 large eggs ¼ cup grated Parmesan cheese Other:\n1 (16 ounce) package lasagna noodles 8 ounces shredded mozzarella cheese, divided Directions Preheat the oven to 350 degrees F (175 degrees C).","title":"Easy Lasagna"},{"content":"Description Just a little enchilada recipe.\nIngredients 1 tablespoon olive oil 1 green pepper, chopped 1 medium onion, chopped 3 garlic cloves, minced 1 pound ground beef 1 can (15 ounces) black beans, rinsed and drained 1 can (14-1/2 ounces) diced tomatoes and green chiles 1/4 cup picante sauce 1 tablespoon chili powder 1 teaspoon ground cumin 1/4 teaspoon crushed red pepper flakes 2 cups cooked brown rice 8 flour tortillas (6 inches), warmed 1 cup salsa 1 cup shredded reduced-fat cheddar cheese 3 tablespoons chopped fresh cilantro leaves Optional toppings: Cotija cheese, red onion, jalapeno peppers, avocado, lime wedges Directions Preheat oven to 350°. In a large skillet, heat oil over medium heat. Add green pepper, onion, and garlic; cook until tender. Add ground beef; cook and stir until no longer pink. Drain. Stir in black beans, tomatoes, picante sauce, chili powder, cumin, and red pepper flakes. Bring to a boil; reduce heat and simmer. Add cooked rice; simmer for 5 minutes. Spoon the mixture into tortillas, roll them up, and place in a baking dish. Top with salsa and cheese. Bake covered for 25 minutes, then uncovered until cheese melts. Garnish with cilantro and serve with optional toppings. ","permalink":"https://loganpashby.com/recipes/enchiladas/","summary":"Description Just a little enchilada recipe.\nIngredients 1 tablespoon olive oil 1 green pepper, chopped 1 medium onion, chopped 3 garlic cloves, minced 1 pound ground beef 1 can (15 ounces) black beans, rinsed and drained 1 can (14-1/2 ounces) diced tomatoes and green chiles 1/4 cup picante sauce 1 tablespoon chili powder 1 teaspoon ground cumin 1/4 teaspoon crushed red pepper flakes 2 cups cooked brown rice 8 flour tortillas (6 inches), warmed 1 cup salsa 1 cup shredded reduced-fat cheddar cheese 3 tablespoons chopped fresh cilantro leaves Optional toppings: Cotija cheese, red onion, jalapeno peppers, avocado, lime wedges Directions Preheat oven to 350°.","title":"Enchiladas (WIP)"},{"content":"Description My favorite thai noods recipe.\nIngredients 1 pound linguine 2 TBS olive oil , divided 2 large eggs , lightly beaten ½ teaspoon crushed red pepper flakes 1 zucchini , cut in half vertically, then sliced in half circles 8 ounces mushroom , chopped 3 cloves garlic , minced 2 TBS brown sugar ⅓ cup low sodium soy sauce 1.5 TBS Sriracha hot sauce (this is A LOT of spice, tone it down if you don\u0026rsquo;t like spicy) 2 inches fresh ginger , grated 1 handful fresh cilantro , chopped 4 green onions , chopped ¼ cup peanuts , chopped Directions In a large stock pot, fill halfway with water, salt, and bring to a boil. Add linguine and cook according to package directions. Drain and set aside. In a medium bowl combine brown sugar, soy sauce, sriracha, and ginger; whisk well to combine; set aside. Return large stock pot to stove, heat over medium heat, add 1 TBS olive oil. Add beaten eggs and red pepper flakes and stir to scramble the eggs. Once cooked, set aside with pasta. Return large stock pot to stove, heat remaining 1 TBS oil over medium heat. Add zucchini, mushrooms, and garlic. Saute over medium high heat for 5-6 minutes or until veggies are cooked through. Turn heat down to low, add pasta and eggs back to pot, then pour the sauce mixture over the top. Using a wooden spoon, stir well to coat pasta and vegetables with sauce. Remove from heat, add peanuts, green onions, and cilantro; stir to combine. Serve immediately. ","permalink":"https://loganpashby.com/recipes/thai_noods/","summary":"Description My favorite thai noods recipe.\nIngredients 1 pound linguine 2 TBS olive oil , divided 2 large eggs , lightly beaten ½ teaspoon crushed red pepper flakes 1 zucchini , cut in half vertically, then sliced in half circles 8 ounces mushroom , chopped 3 cloves garlic , minced 2 TBS brown sugar ⅓ cup low sodium soy sauce 1.5 TBS Sriracha hot sauce (this is A LOT of spice, tone it down if you don\u0026rsquo;t like spicy) 2 inches fresh ginger , grated 1 handful fresh cilantro , chopped 4 green onions , chopped ¼ cup peanuts , chopped Directions In a large stock pot, fill halfway with water, salt, and bring to a boil.","title":"Thai Noodles"},{"content":"The simpler the better In software engineering it\u0026rsquo;s a well known principle that the simplest solution is the best. That way, others will be able to understand the solution quickly, and it will be easier to maintain in the future. Even when choosing between simplicity and optimization, simplicity should usually win.\nIt turns out that keeping this in mind, no matter the task, puts your brain in a state that\u0026rsquo;s ready to tackle issues in a better way. Start with \u0026ldquo;this is simple\u0026rdquo; will force you to start from the best potential solutions.\n","permalink":"https://loganpashby.com/blog/think_simply/","summary":"The simpler the better In software engineering it\u0026rsquo;s a well known principle that the simplest solution is the best. That way, others will be able to understand the solution quickly, and it will be easier to maintain in the future. Even when choosing between simplicity and optimization, simplicity should usually win.\nIt turns out that keeping this in mind, no matter the task, puts your brain in a state that\u0026rsquo;s ready to tackle issues in a better way.","title":"Think Simply"},{"content":"Description Ingredients Directions ","permalink":"https://loganpashby.com/recipes/pourover/","summary":"Description Ingredients Directions ","title":"v60 Pourover"},{"content":"Click to see the documentation for jellobot, a discord bot written in asynchronous python. ","permalink":"https://loganpashby.com/projects/jellobot/","summary":"Click to see the documentation for jellobot, a discord bot written in asynchronous python. ","title":"Jellobot"},{"content":"Description Ingredients Directions ","permalink":"https://loganpashby.com/recipes/aeropress/","summary":"Description Ingredients Directions ","title":"Aeropress"},{"content":"As remote learning continues to be the norm, teachers and professors are relying more heavily on recorded lectures to deliver course material to their students. However, recorded lectures can be time-consuming to edit, and cleaning up audio files can be a particular challenge.\nThat\u0026rsquo;s where Autocut comes in. Autocut is an open-source tool designed to automatically clean up recorded lectures, saving teachers and professors valuable time and effort. It\u0026rsquo;s designed to allow a user to upload their lecture video into the tool and Autocut will proceed to edit out silence, dead air, and noise artifacts from audio files and their accompanying video (if applicable).\nHow Autocut Works Autocut uses pre-trained deep learning models to perform various labeling tasks such as Silence Removal, Automatic Speech Recognition, Forced alignment, and Voice Activity Detection. These models analyze the recorded lecture, identifying and removing unwanted sounds, such as background noise, coughs, and sneezes. The result is a cleaner, more professional-sounding recording that is easier for students to follow.\nProject Components Autocut consists of four main components:\n1. Label Studio Front-End The Label Studio (LS) front-end is mostly unchanged, but we had to connect it to our custom LS backend API and set up the XML interface to visualize everything the user might be interested in.\n2. Label Studio Backend The Label Studio Backend implements a required LS class so that the LS front-end knows how to retrieve predictions. The main logic goes in the \u0026ldquo;predict\u0026rdquo; method. In the latest iteration of the product, there are several pre-trained DL models being used for various labeling tasks such as Silence Removal, Automatic Speech Recognition, Forced alignment, and Voice Activity Detection.\n3. Flask API The Flask API responds to the submit button from the LS front-end and calls the appropriate video editing scripts. Additionally, this API accepts the uploaded file from the landing page UI and stores it so that it can make edits to the file later on (for which we use ffmpeg). The Flask API also sends emails to users, including verification codes and project links upon inference completion.\n4. Landing Page The landing page is responsible for accepting uploaded files from users and presenting them with a user-friendly interface for labeling the file. For this, we used a bare-bones React app to enable user management and file upload before proceeding to route them to LS.\nCluster Compute All inference in Autocut is done on the WWU cluster computer. The machine learning backend API will scp the current video file. The ML backend calls the inference script over SSH and then remains idle, leaving the LS front-end waiting until the ML finishes. The outputs labels are a synthesis of the various model outputs that we can translate into information about which areas of the video/audio file to delete, speed up, mute, etc. Finally, the cluster \u0026ldquo;cleans up\u0026rdquo; by deleting the video and label files because all data management should happen on the home server side.\nInstallation Instructions for installing label-studio as a dev:\nMake sure you are inside of the ml_autocut21 repo\nClone the fork of label-studio\ngit clone https://github.com/TrevORtega/label-studio.git\ncd label-studio\n^This will create a git submodule inside of the repository. Use git status to check which repo you are in if it is confusing.\nInstall required dependencies and run ( if there are no front-end changes ) # Install all package dependencies pip install -e . # Run database migrations python label_studio/manage.py migrate # Start the server in development mode at http://localhost:8080 python label_studio/manage.py runserver This is how we apply and view front-end changes if we make them cd label_studio/frontend/ npm ci npx webpack cd ../.. python label_studio/manage.py collectstatic --no-input To use our specific models in Label Studio:\n(If first time) Follow the directions in the Label Studio ML backend repository to install as dev: https://github.com/heartexlabs/label-studio-ml-backend\nrun:\nlabel-studio-ml init dafdl_backend --script src/LS-audio-segment-model.py label-studio-ml start dafdl_backend Create a new project in label studio (should still be running on http://localhost:8080)\nIn project settings add a new ML Backend with http://localhost:9090 as url.\nTurn on automatic annotations\nUse custom labeling config:\n\u0026lt;View\u0026gt; \u0026lt;Labels name=\u0026#34;labels\u0026#34; toName=\u0026#34;audio\u0026#34;\u0026gt; \u0026lt;Label value=\u0026#34;Speaker 1\u0026#34; /\u0026gt; \u0026lt;Label value=\u0026#34;Speaker 2\u0026#34; /\u0026gt; \u0026lt;/Labels\u0026gt; \u0026lt;AudioPlus name=\u0026#34;audio\u0026#34; value=\u0026#34;$audio\u0026#34;/\u0026gt; \u0026lt;View visibleWhen=\u0026#34;region-selected\u0026#34;\u0026gt; \u0026lt;Header value=\u0026#34;Provide Transcription\u0026#34; /\u0026gt; \u0026lt;/View\u0026gt; \u0026lt;TextArea name=\u0026#34;transcription\u0026#34; toName=\u0026#34;audio\u0026#34; rows=\u0026#34;2\u0026#34; editable=\u0026#34;true\u0026#34; perRegion=\u0026#34;true\u0026#34; required=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;TextArea name=\u0026#34;transcription2\u0026#34; toName=\u0026#34;audio\u0026#34; rows=\u0026#34;2\u0026#34; editable=\u0026#34;true\u0026#34; required=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/View\u0026gt; Import data and view the automatic predictions!\nFAQs Why Label Studio? We chose Label Studio because it had a built-out front-end and labeling capabilities already set. We considered other styles of software to build off of such as open-source video editing, but ultimately decided against this because these projects are massive and too complex for what we were trying to accomplish. Competing tools at this task were either lacking in ML support or were too rudimentary to be built into a software product at the scale we were interested in.\nWhy not passwords? We chose not to implement a password system as we didn\u0026rsquo;t want to be responsible for user password storage. Instead, we felt that the code verification system was sufficient.\nWhy Autocut? Autocut is an open-source tool that can help teachers and professors save time and effort in editing their recorded lectures. By using pre-trained deep learning models to clean up recorded lectures, Autocut makes it easier for teachers and professors to provide high-quality course material to their students. Whether you\u0026rsquo;re a teacher or professor looking to improve your recorded lectures, Autocut is an excellent tool to help you achieve your goals.\nCan I see the code? Yes! However, since it was a school project we had to make the repo private. Get in touch with me and I can get you access.\nFuture Work and Ideas While Autocut is a powerful tool for automatically cleaning up recorded lectures, there is still room for improvement and expansion. Here are some potential areas for future work and ideas for Autocut:\n1. Speech Enhancement In addition to removing unwanted sounds, Autocut could be expanded to enhance speech quality. For example, it could adjust the volume of the speaker\u0026rsquo;s voice to make it more consistent or apply filters to improve clarity.\n2. Transcription Autocut could also be expanded to provide automatic transcription of recorded lectures. By combining speech recognition with labeling tasks, Autocut could generate a transcript of the lecture, making it easier for students to follow along and review the material.\n3. Integration with Learning Management Systems To make it even easier for teachers and professors to deliver high-quality course material, Autocut could be integrated with popular learning management systems like Blackboard, Canvas, or Moodle. This would allow teachers and professors to upload and clean up recorded lectures directly from their LMS, without the need for additional steps.\n4. Integration with Video Editing Software While Autocut is designed to be a standalone tool, it could also be integrated with popular video editing software like Adobe Premiere or Final Cut Pro. This would allow teachers and professors to clean up recorded lectures and make additional edits in the same software, streamlining the editing process even further.\nOverall, there are many potential areas for future work and ideas for Autocut. As remote learning continues to be the norm, Autocut has the potential to become an essential tool for teachers and professors looking to deliver high-quality course material to their students.\n","permalink":"https://loganpashby.com/projects/autocut/","summary":"As remote learning continues to be the norm, teachers and professors are relying more heavily on recorded lectures to deliver course material to their students. However, recorded lectures can be time-consuming to edit, and cleaning up audio files can be a particular challenge.\nThat\u0026rsquo;s where Autocut comes in. Autocut is an open-source tool designed to automatically clean up recorded lectures, saving teachers and professors valuable time and effort. It\u0026rsquo;s designed to allow a user to upload their lecture video into the tool and Autocut will proceed to edit out silence, dead air, and noise artifacts from audio files and their accompanying video (if applicable).","title":"Autocut"},{"content":"Introduction In this blog post, I\u0026rsquo;ll discuss our award-winning hackathon project from the 2021 Western Washington University Hackathon. Our team developed a web application called Fictionary that generates fictitious definitions for coherent words. We\u0026rsquo;ll guide you through the process of building this app, which consists of a large language model, a website, and an API that passes information between the two. We\u0026rsquo;ll also share code examples, images, and insights into our project\u0026rsquo;s development.\nLanguage Model: Fine-Tuning GPT-2 To create Fictionary, we fine-tuned the GPT-2 language model (which we got from hugging face 🤗) on dictionary data to train it to generate new definitions for given words. We compared the results between fine-tuning on Urban Dictionary and the Online Plain Text English Dictionary. Ultimately, we decided to go with Urban Dictionary as the dataset was significantly larger and provided more entertaining definitions.\nData Cleaning and Profanity Check To get the data into a usable format, we downloaded all of Urban Dictionary to a CSV and used pandas to remove duplicates, extremely vulgar definitions, etc. We applied a profanity check in two places to the data to make the definitions generated from Urban Dictionary less vulgar. The aforementioned data-cleaning phase as well as in the API itself to check the actual generated text. This pared the dataset down to around 2 million word-definition pairs. Here\u0026rsquo;s a snippet of our profanity check code:\ntry: definition = models.define(model, word, num_return=1)[0] definition = definition .replace(\u0026#39;]\u0026#39;, \u0026#39;\u0026#39;) .replace(\u0026#39;[\u0026#39;, \u0026#39;\u0026#39;)\\ .replace(\u0026#39;f***\u0026#39;, \u0026#39;duck\u0026#39;) .replace(\u0026#39;c***\u0026#39;, \u0026#39;trunk\u0026#39;)\\ .replace(\u0026#39;sex\u0026#39;, \u0026#39;love\u0026#39;) if definition[-1] != \u0026#39;.\u0026#39;: definition += \u0026#39;.\u0026#39; except Exception as e: print(e) definition = \u0026#34;This word is undefinable. Good job...\u0026#34; Please note that the model still may generate explicit material occasionally, so use it at your own discretion.\nBuilding the Website We built the website using Node.js and Express for the webserver backend, Handlebars for HTML templating, and Sass for styling. Below is a simplified example of our server setup:\njavascriptCopy codeconst express = require(\u0026#39;express\u0026#39;); const app = express(); var indexRouter = require(\u0026#39;./routes/index\u0026#39;); app.set(\u0026#39;view engine\u0026#39;, \u0026#39;hbs\u0026#39;); app.use(express.static(\u0026#39;public\u0026#39;)); app.use(\u0026#39;/\u0026#39;, indexRouter); app.listen(3000, () =\u0026gt; { console.log(\u0026#39;Fictionary app listening on port 3000!\u0026#39;); }); Twitter and Zazzle API Integration We also integrated the Twitter API for users to tweet about their Fictionary words and the Zazzle API to create a custom mug featuring their words and definition.\nCreating the API with Flask Lastly, we developed an API using the Flask Python framework to communicate between the language model and the website. Here\u0026rsquo;s a basic example of our Flask API setup:\nfrom flask import Flask, request, jsonify import sys sys.path.append(\u0026#39;..\u0026#39;) import models.train as models app = Flask(__name__) # ML model definition loaded_models = { \u0026#39;1\u0026#39;: \u0026#39;data/dict-short.bin\u0026#39;, \u0026#39;2\u0026#39;: \u0026#39;data/dict-long.bin\u0026#39;, \u0026#39;3\u0026#39;: \u0026#39;data/urbandict.bin\u0026#39;, \u0026#39;4\u0026#39;: \u0026#39;data/urbandict-long.bin\u0026#39;, } model = input(f\u0026#34;{loaded_models}\\nEnter model number from above: \u0026#34;) weights = loaded_models[model] model = models.get_model_for_api(weights_path=weights) @app.route(\u0026#39;/word\u0026#39;, methods=[\u0026#34;POST\u0026#34;]) def word(): data = request.json word = data[\u0026#39;word\u0026#39;] definition = models.define(model, word, num_return=1)[0] resp_data = json.dumps( {\u0026#39;definition\u0026#39;: definition} ) response = Response(resp_data) return response @app.route(\u0026#39;/\u0026#39;, methods=[\u0026#34;GET\u0026#34;]) def index(): return redirect(f\u0026#39;http://hackathon.chrisdaw.net:3030\u0026#39;, 301) if __name__ == \u0026#39;__main__\u0026#39;: \u0026#34;\u0026#34;\u0026#34; # Load ML model for k, weights_path in loaded_models.items(): loaded_models[k] = models.get_model(weights_path) \u0026#34;\u0026#34;\u0026#34; app.debug=True app.run(host=\u0026#39;0.0.0.0\u0026#39;) # run our Flask app Fictionary Now Available in React Since its release, I have forked the repo and made various improvements including:\nPorted the app over to React\nSet up permanent hosting on my website for everyone to enjoy\nAdded additional security to the Flask API like authentication\nCall to Action: Try Fictionary Now! We invite you to visit loganpashby.com/fictionary to try Fictionary for yourself. Generate your own unique and entertaining definitions for any words you can imagine and share them with your friends. You can also create a custom mug featuring your word and definition, or tweet your creations to your followers. Have fun, and remember to use Fictionary responsibly!\nThank you for reading our blog post about our award-winning hackathon project. We hope you found it insightful and enjoyable. If you have any questions or suggestions, please feel free to leave a comment below. Happy defining!\n","permalink":"https://loganpashby.com/projects/fictionary/","summary":"Introduction In this blog post, I\u0026rsquo;ll discuss our award-winning hackathon project from the 2021 Western Washington University Hackathon. Our team developed a web application called Fictionary that generates fictitious definitions for coherent words. We\u0026rsquo;ll guide you through the process of building this app, which consists of a large language model, a website, and an API that passes information between the two. We\u0026rsquo;ll also share code examples, images, and insights into our project\u0026rsquo;s development.","title":"Fictionary"}]