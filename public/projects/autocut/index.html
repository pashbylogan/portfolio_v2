<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Autocut | Portfolio</title>
<meta name=keywords content><meta name=description content="As remote learning continues to be the norm, teachers and professors are relying more heavily on recorded lectures to deliver course material to their students. However, recorded lectures can be time-consuming to edit, and cleaning up audio files can be a particular challenge.
That&rsquo;s where Autocut comes in. Autocut is an open-source tool designed to automatically clean up recorded lectures, saving teachers and professors valuable time and effort. It&rsquo;s designed to allow a user to upload their lecture video into the tool and Autocut will proceed to edit out silence, dead air, and noise artifacts from audio files and their accompanying video (if applicable)."><meta name=author content="Me"><link rel=canonical href=https://loganpashby.com/projects/autocut/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://loganpashby.com/logo.svg><link rel=icon type=image/png sizes=16x16 href=https://loganpashby.com/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://loganpashby.com/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://loganpashby.com/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://loganpashby.com/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZJHHBY6NHZ"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-ZJHHBY6NHZ",{anonymize_ip:!1})}</script><meta property="og:title" content="Autocut"><meta property="og:description" content="As remote learning continues to be the norm, teachers and professors are relying more heavily on recorded lectures to deliver course material to their students. However, recorded lectures can be time-consuming to edit, and cleaning up audio files can be a particular challenge.
That&rsquo;s where Autocut comes in. Autocut is an open-source tool designed to automatically clean up recorded lectures, saving teachers and professors valuable time and effort. It&rsquo;s designed to allow a user to upload their lecture video into the tool and Autocut will proceed to edit out silence, dead air, and noise artifacts from audio files and their accompanying video (if applicable)."><meta property="og:type" content="article"><meta property="og:url" content="https://loganpashby.com/projects/autocut/"><meta property="og:image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1682860188524/b1370476-d015-4cb4-90c9-c2a40a0b4fb7.png"><meta property="article:section" content="projects"><meta property="article:published_time" content="2023-04-30T13:00:46-07:00"><meta property="article:modified_time" content="2023-04-30T13:00:46-07:00"><meta property="og:site_name" content="LoganPashby"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://cdn.hashnode.com/res/hashnode/image/upload/v1682860188524/b1370476-d015-4cb4-90c9-c2a40a0b4fb7.png"><meta name=twitter:title content="Autocut"><meta name=twitter:description content="As remote learning continues to be the norm, teachers and professors are relying more heavily on recorded lectures to deliver course material to their students. However, recorded lectures can be time-consuming to edit, and cleaning up audio files can be a particular challenge.
That&rsquo;s where Autocut comes in. Autocut is an open-source tool designed to automatically clean up recorded lectures, saving teachers and professors valuable time and effort. It&rsquo;s designed to allow a user to upload their lecture video into the tool and Autocut will proceed to edit out silence, dead air, and noise artifacts from audio files and their accompanying video (if applicable)."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Projects","item":"https://loganpashby.com/projects/"},{"@type":"ListItem","position":2,"name":"Autocut","item":"https://loganpashby.com/projects/autocut/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Autocut","name":"Autocut","description":"As remote learning continues to be the norm, teachers and professors are relying more heavily on recorded lectures to deliver course material to their students. However, recorded lectures can be time-consuming to edit, and cleaning up audio files can be a particular challenge.\nThat\u0026rsquo;s where Autocut comes in. Autocut is an open-source tool designed to automatically clean up recorded lectures, saving teachers and professors valuable time and effort. It\u0026rsquo;s designed to allow a user to upload their lecture video into the tool and Autocut will proceed to edit out silence, dead air, and noise artifacts from audio files and their accompanying video (if applicable).","keywords":[],"articleBody":"As remote learning continues to be the norm, teachers and professors are relying more heavily on recorded lectures to deliver course material to their students. However, recorded lectures can be time-consuming to edit, and cleaning up audio files can be a particular challenge.\nThat’s where Autocut comes in. Autocut is an open-source tool designed to automatically clean up recorded lectures, saving teachers and professors valuable time and effort. It’s designed to allow a user to upload their lecture video into the tool and Autocut will proceed to edit out silence, dead air, and noise artifacts from audio files and their accompanying video (if applicable).\nHow Autocut Works Autocut uses pre-trained deep learning models to perform various labeling tasks such as Silence Removal, Automatic Speech Recognition, Forced alignment, and Voice Activity Detection. These models analyze the recorded lecture, identifying and removing unwanted sounds, such as background noise, coughs, and sneezes. The result is a cleaner, more professional-sounding recording that is easier for students to follow.\nProject Components Autocut consists of four main components:\n1. Label Studio Front-End The Label Studio (LS) front-end is mostly unchanged, but we had to connect it to our custom LS backend API and set up the XML interface to visualize everything the user might be interested in.\n2. Label Studio Backend The Label Studio Backend implements a required LS class so that the LS front-end knows how to retrieve predictions. The main logic goes in the “predict” method. In the latest iteration of the product, there are several pre-trained DL models being used for various labeling tasks such as Silence Removal, Automatic Speech Recognition, Forced alignment, and Voice Activity Detection.\n3. Flask API The Flask API responds to the submit button from the LS front-end and calls the appropriate video editing scripts. Additionally, this API accepts the uploaded file from the landing page UI and stores it so that it can make edits to the file later on (for which we use ffmpeg). The Flask API also sends emails to users, including verification codes and project links upon inference completion.\n4. Landing Page The landing page is responsible for accepting uploaded files from users and presenting them with a user-friendly interface for labeling the file. For this, we used a bare-bones React app to enable user management and file upload before proceeding to route them to LS.\nCluster Compute All inference in Autocut is done on the WWU cluster computer. The machine learning backend API will scp the current video file. The ML backend calls the inference script over SSH and then remains idle, leaving the LS front-end waiting until the ML finishes. The outputs labels are a synthesis of the various model outputs that we can translate into information about which areas of the video/audio file to delete, speed up, mute, etc. Finally, the cluster “cleans up” by deleting the video and label files because all data management should happen on the home server side.\nInstallation Instructions for installing label-studio as a dev:\nMake sure you are inside of the ml_autocut21 repo\nClone the fork of label-studio\ngit clone https://github.com/TrevORtega/label-studio.git\ncd label-studio\n^This will create a git submodule inside of the repository. Use git status to check which repo you are in if it is confusing.\nInstall required dependencies and run ( if there are no front-end changes ) # Install all package dependencies pip install -e . # Run database migrations python label_studio/manage.py migrate # Start the server in development mode at http://localhost:8080 python label_studio/manage.py runserver This is how we apply and view front-end changes if we make them cd label_studio/frontend/ npm ci npx webpack cd ../.. python label_studio/manage.py collectstatic --no-input To use our specific models in Label Studio:\n(If first time) Follow the directions in the Label Studio ML backend repository to install as dev: https://github.com/heartexlabs/label-studio-ml-backend\nrun:\nlabel-studio-ml init dafdl_backend --script src/LS-audio-segment-model.py label-studio-ml start dafdl_backend Create a new project in label studio (should still be running on http://localhost:8080)\nIn project settings add a new ML Backend with http://localhost:9090 as url.\nTurn on automatic annotations\nUse custom labeling config:\n","wordCount":"1212","inLanguage":"en","image":"https://cdn.hashnode.com/res/hashnode/image/upload/v1682860188524/b1370476-d015-4cb4-90c9-c2a40a0b4fb7.png","datePublished":"2023-04-30T13:00:46-07:00","dateModified":"2023-04-30T13:00:46-07:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://loganpashby.com/projects/autocut/"},"publisher":{"@type":"Organization","name":"Portfolio","logo":{"@type":"ImageObject","url":"https://loganpashby.com/logo.svg"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://loganpashby.com/ accesskey=h title="Home (Alt + H)"><img src=https://loganpashby.com/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://loganpashby.com/projects/ title=projects><span>projects</span></a></li><li><a href=https://loganpashby.com/blog/ title=blog><span>blog</span></a></li><li><a href=https://loganpashby.com/recipes/ title=recipes><span>recipes</span></a></li><li><a href=https://loganpashby.com/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://loganpashby.com/>Home</a>&nbsp;»&nbsp;<a href=https://loganpashby.com/projects/>Projects</a></div><h1 class="post-title entry-hint-parent">Autocut</h1><div class=post-meta><span title='2023-04-30 13:00:46 -0700 -0700'>April 30, 2023</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1212 words&nbsp;·&nbsp;Me&nbsp;|&nbsp;<a href=https://github.com/pashbylogan/hugo_portfolio/content/projects/autocut.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#how-autocut-works><strong>How Autocut Works</strong></a></li><li><a href=#project-components><strong>Project Components</strong></a><ul><li><a href=#1-label-studio-front-end><strong>1. Label Studio</strong> Front-End</a></li><li><a href=#2-label-studio-backend><strong>2. Label Studio Backend</strong></a></li><li><a href=#3-flask-api><strong>3. Flask API</strong></a></li><li><a href=#4-landing-page><strong>4. Landing Page</strong></a></li></ul></li><li><a href=#cluster-compute><strong>Cluster Compute</strong></a></li><li><a href=#installation>Installation</a></li><li><a href=#faqs>FAQs</a><ul><li><a href=#why-label-studio><strong>Why Label Studio?</strong></a></li><li><a href=#why-not-passwords><strong>Why not passwords?</strong></a></li><li><a href=#why-autocut><strong>Why Autocut?</strong></a></li><li><a href=#can-i-see-the-code>Can I see the code?</a></li></ul></li><li><a href=#future-work-and-ideas><strong>Future Work and Ideas</strong></a><ul><li><a href=#1-speech-enhancement><strong>1. Speech Enhancement</strong></a></li><li><a href=#2-transcription><strong>2. Transcription</strong></a></li><li><a href=#3-integration-with-learning-management-systems><strong>3. Integration with Learning Management Systems</strong></a></li><li><a href=#4-integration-with-video-editing-software><strong>4. Integration with Video Editing Software</strong></a></li></ul></li></ul></nav></div></details></div><div class=post-content><p>As remote learning continues to be the norm, teachers and professors are relying more heavily on recorded lectures to deliver course material to their students. However, recorded lectures can be time-consuming to edit, and cleaning up audio files can be a particular challenge.</p><p>That&rsquo;s where Autocut comes in. Autocut is an open-source tool designed to automatically clean up recorded lectures, saving teachers and professors valuable time and effort. It&rsquo;s designed to allow a user to upload their lecture video into the tool and Autocut will proceed to edit out silence, dead air, and noise artifacts from audio files and their accompanying video (if applicable).</p><h2 id=how-autocut-works><strong>How Autocut Works</strong><a hidden class=anchor aria-hidden=true href=#how-autocut-works>#</a></h2><p>Autocut uses pre-trained deep learning models to perform various labeling tasks such as Silence Removal, Automatic Speech Recognition, Forced alignment, and Voice Activity Detection. These models analyze the recorded lecture, identifying and removing unwanted sounds, such as background noise, coughs, and sneezes. The result is a cleaner, more professional-sounding recording that is easier for students to follow.</p><figure><img loading=lazy src=https://cdn.hashnode.com/res/hashnode/image/upload/v1682868048308/cd013aa9-0244-40ae-81a0-b87bb665db4a.png></figure><h2 id=project-components><strong>Project Components</strong><a hidden class=anchor aria-hidden=true href=#project-components>#</a></h2><p>Autocut consists of four main components:</p><h3 id=1-label-studio-front-end><strong>1. Label Studio</strong> Front-End<a hidden class=anchor aria-hidden=true href=#1-label-studio-front-end>#</a></h3><p>The <a href=https://labelstud.io/>Label Studio</a> (LS) front-end is mostly unchanged, but we had to connect it to our custom LS backend API and set up the XML interface to visualize everything the user might be interested in.</p><figure><img loading=lazy src="https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fdocs.primehub.io%2Fdocs%2Fassets%2Fapp_tutorial_labelstudio_login_page.png&amp;f=1&amp;nofb=1&amp;ipt=066c2fc7d67847d053295854b910e0cd25c240a6d5db3cd53e30833f17717e1f&amp;ipo=images"></figure><h3 id=2-label-studio-backend><strong>2. Label Studio Backend</strong><a hidden class=anchor aria-hidden=true href=#2-label-studio-backend>#</a></h3><p>The Label Studio Backend implements a required LS class so that the LS front-end knows how to retrieve predictions. The main logic goes in the &ldquo;predict&rdquo; method. In the latest iteration of the product, there are several pre-trained DL models being used for various labeling tasks such as Silence Removal, Automatic Speech Recognition, Forced alignment, and Voice Activity Detection.</p><h3 id=3-flask-api><strong>3. Flask API</strong><a hidden class=anchor aria-hidden=true href=#3-flask-api>#</a></h3><p>The Flask API responds to the submit button from the LS front-end and calls the appropriate video editing scripts. Additionally, this API accepts the uploaded file from the landing page UI and stores it so that it can make edits to the file later on (for which we use <a href=https://ffmpeg.org/>ffmpeg</a>). The Flask API also sends emails to users, including verification codes and project links upon inference completion.</p><h3 id=4-landing-page><strong>4. Landing Page</strong><a hidden class=anchor aria-hidden=true href=#4-landing-page>#</a></h3><p>The landing page is responsible for accepting uploaded files from users and presenting them with a user-friendly interface for labeling the file. For this, we used a bare-bones React app to enable user management and file upload before proceeding to route them to LS.</p><figure><img loading=lazy src=https://cdn.hashnode.com/res/hashnode/image/upload/v1682867114694/d0c040ad-0c06-42c7-aea3-eec19749d924.png></figure><h2 id=cluster-compute><strong>Cluster Compute</strong><a hidden class=anchor aria-hidden=true href=#cluster-compute>#</a></h2><p>All inference in Autocut is done on the WWU cluster computer. The machine learning backend API will scp the current video file. The ML backend calls the inference script over SSH and then remains idle, leaving the LS front-end waiting until the ML finishes. The outputs labels are a synthesis of the various model outputs that we can translate into information about which areas of the video/audio file to delete, speed up, mute, etc. Finally, the cluster &ldquo;cleans up&rdquo; by deleting the video and label files because all data management should happen on the home server side.</p><h2 id=installation>Installation<a hidden class=anchor aria-hidden=true href=#installation>#</a></h2><p><strong>Instructions for installing label-studio as a dev:</strong></p><ol><li><p>Make sure you are inside of the ml_autocut21 repo</p></li><li><p>Clone the fork of label-studio</p></li></ol><p><code>git clone</code> <a href=https://github.com/TrevORtega/label-studio.git><code>https://github.com/TrevORtega/label-studio.git</code></a></p><p><code>cd label-studio</code></p><p>^This will create a git submodule inside of the repository. Use git status to check which repo you are in if it is confusing.</p><ol><li>Install required dependencies and run ( if there are no front-end changes )</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Install all package dependencies</span>
</span></span><span class=line><span class=cl>pip install -e .
</span></span><span class=line><span class=cl><span class=c1># Run database migrations</span>
</span></span><span class=line><span class=cl>python label_studio/manage.py migrate
</span></span><span class=line><span class=cl><span class=c1># Start the server in development mode at http://localhost:8080 </span>
</span></span><span class=line><span class=cl>python label_studio/manage.py runserver
</span></span></code></pre></div><ol><li>This is how we apply and view front-end changes if we make them</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> label_studio/frontend/
</span></span><span class=line><span class=cl>npm ci
</span></span><span class=line><span class=cl>npx webpack
</span></span><span class=line><span class=cl><span class=nb>cd</span> ../..
</span></span><span class=line><span class=cl>python label_studio/manage.py collectstatic --no-input
</span></span></code></pre></div><p>To use our specific models in Label Studio:</p><ol><li><p>(If first time) Follow the directions in the Label Studio ML backend repository to install as dev: <a href=https://github.com/heartexlabs/label-studio-ml-backend>https://github.com/heartexlabs/label-studio-ml-backend</a></p></li><li><p>run:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>label-studio-ml init dafdl_backend --script src/LS-audio-segment-model.py
</span></span><span class=line><span class=cl>label-studio-ml start dafdl_backend
</span></span></code></pre></div></li><li><p>Create a new project in label studio (should still be running on <a href=http://localhost:8080>http://localhost:8080</a>)</p></li><li><p>In project settings add a new ML Backend with <a href=http://localhost:9090>http://localhost:9090</a> as url.</p><ul><li><p>Turn on automatic annotations</p></li><li><p>Use custom labeling config:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=cl>    <span class=nt>&lt;View&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;Labels</span> <span class=na>name=</span><span class=s>&#34;labels&#34;</span> <span class=na>toName=</span><span class=s>&#34;audio&#34;</span><span class=nt>&gt;</span>
</span></span><span class=line><span class=cl>          <span class=nt>&lt;Label</span> <span class=na>value=</span><span class=s>&#34;Speaker 1&#34;</span> <span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>          <span class=nt>&lt;Label</span> <span class=na>value=</span><span class=s>&#34;Speaker 2&#34;</span> <span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;/Labels&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;AudioPlus</span> <span class=na>name=</span><span class=s>&#34;audio&#34;</span> <span class=na>value=</span><span class=s>&#34;$audio&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;View</span> <span class=na>visibleWhen=</span><span class=s>&#34;region-selected&#34;</span><span class=nt>&gt;</span>
</span></span><span class=line><span class=cl>          <span class=nt>&lt;Header</span> <span class=na>value=</span><span class=s>&#34;Provide Transcription&#34;</span> <span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;/View&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;TextArea</span> <span class=na>name=</span><span class=s>&#34;transcription&#34;</span> <span class=na>toName=</span><span class=s>&#34;audio&#34;</span>
</span></span><span class=line><span class=cl>                  <span class=na>rows=</span><span class=s>&#34;2&#34;</span> <span class=na>editable=</span><span class=s>&#34;true&#34;</span>
</span></span><span class=line><span class=cl>                  <span class=na>perRegion=</span><span class=s>&#34;true&#34;</span> <span class=na>required=</span><span class=s>&#34;true&#34;</span> <span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;TextArea</span> <span class=na>name=</span><span class=s>&#34;transcription2&#34;</span> <span class=na>toName=</span><span class=s>&#34;audio&#34;</span>
</span></span><span class=line><span class=cl>                  <span class=na>rows=</span><span class=s>&#34;2&#34;</span> <span class=na>editable=</span><span class=s>&#34;true&#34;</span>
</span></span><span class=line><span class=cl>                  <span class=na>required=</span><span class=s>&#34;true&#34;</span> <span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/View&gt;</span>
</span></span></code></pre></div></li></ul></li><li><p>Import data and view the automatic predictions!</p></li></ol><h2 id=faqs>FAQs<a hidden class=anchor aria-hidden=true href=#faqs>#</a></h2><h3 id=why-label-studio><strong>Why Label Studio?</strong><a hidden class=anchor aria-hidden=true href=#why-label-studio>#</a></h3><p>We chose Label Studio because it had a built-out front-end and labeling capabilities already set. We considered other styles of software to build off of such as open-source video editing, but ultimately decided against this because these projects are massive and too complex for what we were trying to accomplish. Competing tools at this task were either lacking in ML support or were too rudimentary to be built into a software product at the scale we were interested in.</p><h3 id=why-not-passwords><strong>Why not passwords?</strong><a hidden class=anchor aria-hidden=true href=#why-not-passwords>#</a></h3><p>We chose not to implement a password system as we didn&rsquo;t want to be responsible for user password storage. Instead, we felt that the code verification system was sufficient.</p><h3 id=why-autocut><strong>Why Autocut?</strong><a hidden class=anchor aria-hidden=true href=#why-autocut>#</a></h3><p>Autocut is an open-source tool that can help teachers and professors save time and effort in editing their recorded lectures. By using pre-trained deep learning models to clean up recorded lectures, Autocut makes it easier for teachers and professors to provide high-quality course material to their students. Whether you&rsquo;re a teacher or professor looking to improve your recorded lectures, Autocut is an excellent tool to help you achieve your goals.</p><h3 id=can-i-see-the-code>Can I see the code?<a hidden class=anchor aria-hidden=true href=#can-i-see-the-code>#</a></h3><p>Yes! However, since it was a school project we had to make the repo private. Get in touch with me and I can get you access.</p><h2 id=future-work-and-ideas><strong>Future Work and Ideas</strong><a hidden class=anchor aria-hidden=true href=#future-work-and-ideas>#</a></h2><p>While Autocut is a powerful tool for automatically cleaning up recorded lectures, there is still room for improvement and expansion. Here are some potential areas for future work and ideas for Autocut:</p><h3 id=1-speech-enhancement><strong>1. Speech Enhancement</strong><a hidden class=anchor aria-hidden=true href=#1-speech-enhancement>#</a></h3><p>In addition to removing unwanted sounds, Autocut could be expanded to enhance speech quality. For example, it could adjust the volume of the speaker&rsquo;s voice to make it more consistent or apply filters to improve clarity.</p><h3 id=2-transcription><strong>2. Transcription</strong><a hidden class=anchor aria-hidden=true href=#2-transcription>#</a></h3><p>Autocut could also be expanded to provide automatic transcription of recorded lectures. By combining speech recognition with labeling tasks, Autocut could generate a transcript of the lecture, making it easier for students to follow along and review the material.</p><h3 id=3-integration-with-learning-management-systems><strong>3. Integration with Learning Management Systems</strong><a hidden class=anchor aria-hidden=true href=#3-integration-with-learning-management-systems>#</a></h3><p>To make it even easier for teachers and professors to deliver high-quality course material, Autocut could be integrated with popular learning management systems like Blackboard, Canvas, or Moodle. This would allow teachers and professors to upload and clean up recorded lectures directly from their LMS, without the need for additional steps.</p><h3 id=4-integration-with-video-editing-software><strong>4. Integration with Video Editing Software</strong><a hidden class=anchor aria-hidden=true href=#4-integration-with-video-editing-software>#</a></h3><p>While Autocut is designed to be a standalone tool, it could also be integrated with popular video editing software like Adobe Premiere or Final Cut Pro. This would allow teachers and professors to clean up recorded lectures and make additional edits in the same software, streamlining the editing process even further.</p><p>Overall, there are many potential areas for future work and ideas for Autocut. As remote learning continues to be the norm, Autocut has the potential to become an essential tool for teachers and professors looking to deliver high-quality course material to their students.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://loganpashby.com/>Portfolio</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>